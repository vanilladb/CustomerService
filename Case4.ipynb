{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 4 說明\n",
    "對每一個 user input 執行 RAG\n",
    "\n",
    "對每一個 input 執行 retrieve flow and related QA\n",
    "\n",
    "假定 user 會不按理回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from tabulate import tabulate\n",
    "client = OpenAI()\n",
    "OpenAI.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_52828\\2711399014.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "csv_file = 'data\\embeddingsV3_3072.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "data = df.to_numpy()\n",
    "\n",
    "index = faiss.IndexFlatL2(data.shape[1])\n",
    "index.add(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_qa(input):\n",
    "    response = client.embeddings.create(input=input, model=\"text-embedding-3-large\", dimensions=3072)\n",
    "    question = np.array(response.data[0].embedding, ndmin=2)\n",
    "    k = 3\n",
    "    distances, indices = index.search(question, k)\n",
    "    csv_question = 'data\\manual.csv'\n",
    "    qdf = pd.read_csv(csv_question)\n",
    "    qarray = qdf.to_numpy()\n",
    "    answer = [(qarray[i], float(dist)) for dist, i in zip(distances[0], indices[0])]\n",
    "    history = \"\"\n",
    "    min_distance = 1\n",
    "    Qcount = 0\n",
    "    for i in range(0,k):\n",
    "        if answer[i][1]<min_distance:\n",
    "            Qcount+=1\n",
    "            history = history +str(i+1)+\". \"+ answer[i][0][0]+\"\\n\"+answer[i][0][1]+\"\\n\"\n",
    "    return Qcount, history\n",
    "\n",
    "def get_similar_flow(input):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. You are Flora customer service chat bot.2. When user ask a question, you must follow the steps, resolving the problem one step at a time.3. If the user asks another question before the previous question is solved, deal with the new question first and then go back to the steps of the previous question for continued processing.\n"
     ]
    }
   ],
   "source": [
    "instructions = [\n",
    "    \"1. You are Flora customer service chat bot.\",\n",
    "    \"2. When user ask a question, you must follow the steps, resolving the problem one step at a time.\",\n",
    "    \"3. If the user asks another question before the previous question is solved, deal with the new question first and then go back to the steps of the previous question for continued processing.\",\n",
    "]\n",
    "\n",
    "instruction = \"\"\n",
    "for i in instructions:\n",
    "    instruction += i\n",
    "\n",
    "print(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Flora's Customer Service\",\n",
    "    instructions=instruction,\n",
    "    model=\"gpt-3.5-turbo-1106\"\n",
    "    # tools = [\n",
    "    #     {\n",
    "    #         \"type\": \"function\",\n",
    "    #         \"function\": {\n",
    "    #             \"name\": \"get_history_question_and_answer\",\n",
    "    #             \"description\": \"Get 1 to 3 history questions and answers that is similar to current question\",\n",
    "    #             \"parameters\": {\n",
    "    #                 \"type\": \"object\",\n",
    "    #                 \"properties\": {\n",
    "    #                     \"current_question\": {\n",
    "    #                         \"type\": \"string\",\n",
    "    #                         \"description\": \"user's question\"\n",
    "    #                     }\n",
    "    #                 },\n",
    "    #                 \"required\": [\"current_question\"]\n",
    "    #             }\n",
    "    #         }\n",
    "    #     }\n",
    "    # ]\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow1 = [\n",
    "#     \"Follow the steps to answer questions:\",\n",
    "#     \"Ask the user for their email.\",\n",
    "#     \"Ask the user for the time when the tree was killed.\",\n",
    "#     \"The last step, you must respond based on the reference answer of the user's initial question if history questions and reference answers are provided. If not, you must reply only a special mark:'*'.\"\n",
    "# ]\n",
    "\n",
    "# flow2 = [\n",
    "#     \"Follow the steps to answer questions:\",\n",
    "#     \"Ask the user for their ID.\",\n",
    "#     \"Ask the user for their user name.\",\n",
    "#     \"The last step, you must respond based on the reference answer of the user's initial question if history questions and reference answers are provided. If not, you must reply only a special mark:'*'.\"\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ask user for their email;\n",
    "if(got user email){\n",
    "    ask user for the time when the tree was killed;\n",
    "    if(got the time){\n",
    "        respond based on the reference answer of the user's initial question if history questions and reference answers are provided. If not, you must reply only a special mark:'*'.\n",
    "    }\n",
    "    else{\n",
    "        ask the time again.\n",
    "    }\n",
    "}\n",
    "else{ask email again}\n",
    "\n",
    "ask user for their ID;\n",
    "if(got user ID){\n",
    "    ask user for the user name;\n",
    "    if(got the user user name){\n",
    "        respond based on the reference answer of the user's initial question if history questions and reference answers are provided. If not, you must reply only a special mark:'*'.\n",
    "    }\n",
    "    else{\n",
    "        ask the user name again.\n",
    "    }\n",
    "}\n",
    "else{ask ID again}\n",
    "'''\n",
    "\n",
    "flow1 = \"ask user for their email;if(got user email){ask user for the time when the tree was killed;if(got the time){respond based on the reference answer of the user's initial question if history questions and reference answers are provided. If not, you must reply only a special mark:'*'.}else{ask the time again.}}else{ask email again}\"\n",
    "flow2 = \"ask user for their ID;if(got user ID){ask user for the user name;if(got the user user name){respond based on the reference answer of the user's initial question if history questions and reference answers are provided. If not, you must reply only a special mark:'*'.}else{ask the user name again.}}else{ask ID again}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"Answer the user according to this process: \" + get_similar_flow(flow) + get_similar_qa(user_input)\n",
    "\n",
    "# prompt = \"\"\n",
    "\n",
    "# Change the comments for this part of the code.\n",
    "\n",
    "# for i in flow1:\n",
    "#     prompt = prompt + i + \"\\n\"\n",
    "\n",
    "# for i in flow2:\n",
    "#     prompt = prompt + i + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\n",
    "\n",
    "prompt += flow1\n",
    "\n",
    "# prompt += flow2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_input = \"I accidentally killed my tree. Is there any way to restore it?\"\n",
    "# user_input = \"How do I find out which email I've linked to?\"\n",
    "# user_input = \"abc123\"\n",
    "# user_input = \"I just found out what email I've linked to. So how do I restore the tree?\"\n",
    "# user_input = \"123@gmail.com\"\n",
    "user_input = \"It's around 4:00 PM on March 28th.\"\n",
    "\n",
    "similar_qa = get_similar_qa(user_input)\n",
    "\n",
    "similar_flow = get_similar_flow(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ask user for their email;if(got user email){ask user for the time when the tree was killed;if(got the time){respond based on the reference answer of the user's initial question if history questions and reference answers are provided. If not, you must reply only a special mark:'*'.}else{ask the time again.}}else{ask email again}It's around 4:00 PM on March 28th.\n"
     ]
    }
   ],
   "source": [
    "# prompt = \"Answer the user according to this process: \" + get_similar_flow(flow) + get_similar_qa(user_input)\n",
    "\n",
    "if similar_qa[0] > 0:\n",
    "    prompt += \"\\nHere is \" + str(similar_qa[0]) + \" history questions and answers related to this question according to Flora's database:\\n\" + similar_qa[1] + \"Here is the question:\\n\"\n",
    "\n",
    "prompt += user_input\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content = prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "while run.status == \"queued\" or run.status == \"in_progress\":\n",
    "    run = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id\n",
    "    )\n",
    "print(run.status)\n",
    "# print(tabulate(run,headers=['run','content'],tablefmt='simple_outline'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)\n",
    "messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id,\n",
    "    order='asc'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for providing your email. Now, could you please tell me the time when the tree was killed?\n",
      "==========\n",
      "ask user for their email;if(got user email){ask user for the time when the tree was killed;if(got the time){respond based on the reference answer of the user's initial question if history questions and reference answers are provided. If not, you must reply only a special mark:'*'.}else{ask the time again.}}else{ask email again}It's around 4:00 PM on March 28th.\n",
      "==========\n",
      "Thank you for providing the time. Based on the information you've provided, it seems like you accidentally killed a tree on Flora. Unfortunately, as per Flora's policy, there is currently no way to restore a dead tree. However, you can report a 'False Detection' by pressing the '!' (triangular exclamation) button at the upper-right corner of the red focus screen. If it is verified to be a false detection, Flora will revive your tree. Alternatively, you can reach out to Flora's support team for further assistance.\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "for i in messages.data[-3:]:\n",
    "    print(i.content[0].text.value)\n",
    "    print(\"==========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AssistantDeleted(id='asst_AJBiezJAOK6RACfUL32Dbadr', deleted=True, object='assistant.deleted')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# client.beta.assistants.delete(assistant.id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VScode-env-3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
