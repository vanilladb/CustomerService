{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 4 說明\n",
    "對每一個 user input 執行 RAG\n",
    "\n",
    "對每一個 input 執行 retrieve flow and related QA\n",
    "\n",
    "假定 user 會不按理回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from tabulate import tabulate\n",
    "client = OpenAI()\n",
    "OpenAI.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "csv_file = 'data\\embeddingsV3_3072.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "data = df.to_numpy()\n",
    "\n",
    "index = faiss.IndexFlatL2(data.shape[1])\n",
    "index.add(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_qa(input):\n",
    "    response = client.embeddings.create(input=input, model=\"text-embedding-3-large\", dimensions=3072)\n",
    "    question = np.array(response.data[0].embedding, ndmin=2)\n",
    "    k = 3\n",
    "    distances, indices = index.search(question, k)\n",
    "    csv_question = 'data\\manual.csv'\n",
    "    qdf = pd.read_csv(csv_question)\n",
    "    qarray = qdf.to_numpy()\n",
    "    answer = [(qarray[i], float(dist)) for dist, i in zip(distances[0], indices[0])]\n",
    "    history = \"\"\n",
    "    min_distance = 1\n",
    "    Qcount = 0\n",
    "    for i in range(0,k):\n",
    "        if answer[i][1]<min_distance:\n",
    "            Qcount+=1\n",
    "            history = history +str(i+1)+\". \"+ answer[i][0][0]+\"\\n\"+answer[i][0][1]+\"\\n\"\n",
    "    return Qcount, history\n",
    "\n",
    "def get_similar_flow(input):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = [\n",
    "    \"1. You are Flora customer service chat bot.\",\n",
    "    \"2. When user ask a question, you must follow the steps, resolving the problem one step at a time.\",\n",
    "    \"3. If the user asks another question before the previous question is solved, deal with the new question first and then go back to the steps of the previous question for continued processing.\",\n",
    "]\n",
    "\n",
    "instruction = \"\"\n",
    "for i in instructions:\n",
    "    instruction += i\n",
    "\n",
    "print(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Flora's Customer Service\",\n",
    "    instructions=instruction,\n",
    "    model=\"gpt-3.5-turbo-1106\"\n",
    "    # tools = [\n",
    "    #     {\n",
    "    #         \"type\": \"function\",\n",
    "    #         \"function\": {\n",
    "    #             \"name\": \"get_history_question_and_answer\",\n",
    "    #             \"description\": \"Get 1 to 3 history questions and answers that is similar to current question\",\n",
    "    #             \"parameters\": {\n",
    "    #                 \"type\": \"object\",\n",
    "    #                 \"properties\": {\n",
    "    #                     \"current_question\": {\n",
    "    #                         \"type\": \"string\",\n",
    "    #                         \"description\": \"user's question\"\n",
    "    #                     }\n",
    "    #                 },\n",
    "    #                 \"required\": [\"current_question\"]\n",
    "    #             }\n",
    "    #         }\n",
    "    #     }\n",
    "    # ]\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow1 = [\n",
    "#     \"Follow the steps to answer questions:\",\n",
    "#     \"Ask the user for their email.\",\n",
    "#     \"Ask the user for the time when the tree was killed.\",\n",
    "#     \"The last step, you must respond based on the reference answer of the user's initial question if history questions and reference answers are provided. If not, you must reply only a special mark:'*'.\"\n",
    "# ]\n",
    "\n",
    "# flow2 = [\n",
    "#     \"Follow the steps to answer questions:\",\n",
    "#     \"Ask the user for their ID.\",\n",
    "#     \"Ask the user for their user name.\",\n",
    "#     \"The last step, you must respond based on the reference answer of the user's initial question if history questions and reference answers are provided. If not, you must reply only a special mark:'*'.\"\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ask user for their email;\n",
    "if(got user email){\n",
    "    ask user for the time when the tree was killed;\n",
    "    if(got the time){\n",
    "        respond based on the reference answer of the user's initial question if history questions and reference answers are provided. If not, you must reply only a special mark:'*'.\n",
    "    }\n",
    "    else{\n",
    "        ask the time again.\n",
    "    }\n",
    "}\n",
    "else{ask email again}\n",
    "\n",
    "ask user for their ID;\n",
    "if(got user ID){\n",
    "    ask user for the user name;\n",
    "    if(got the user user name){\n",
    "        respond based on the reference answer of the user's initial question if history questions and reference answers are provided. If not, you must reply only a special mark:'*'.\n",
    "    }\n",
    "    else{\n",
    "        ask the user name again.\n",
    "    }\n",
    "}\n",
    "else{ask ID again}\n",
    "'''\n",
    "\n",
    "flow1 = \"ask user for their email;if(got user email){ask user for the time when the tree was killed;if(got the time){respond based on the reference answer of the user's initial question if history questions and reference answers are provided. If not, you must reply only a special mark:'*'.}else{ask the time again.}}else{ask email again}\"\n",
    "flow2 = \"ask user for their ID;if(got user ID){ask user for the user name;if(got the user user name){respond based on the reference answer of the user's initial question if history questions and reference answers are provided. If not, you must reply only a special mark:'*'.}else{ask the user name again.}}else{ask ID again}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = get_similar_flow(user_input) + get_similar_qa(user_input) + user_input\n",
    "\n",
    "# prompt = \"\"\n",
    "\n",
    "# for i in flow1:\n",
    "#     prompt = prompt + i + \"\\n\"\n",
    "\n",
    "# for i in flow2:\n",
    "#     prompt = prompt + i + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\n",
    "\n",
    "prompt += flow1\n",
    "\n",
    "# prompt += flow2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I accidentally killed my tree. Is there any way to restore it?\"\n",
    "# user_input = \"How do I find out which email I've linked to?\"\n",
    "# user_input = \"abc123\"\n",
    "# user_input = \"I just found out what email I've linked to. So how do I restore the tree?\"\n",
    "# user_input = \"123@gmail.com\"\n",
    "# user_input = \"It's around 4:00 PM on March 28th.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_qa = get_similar_qa(user_input)\n",
    "similar_flow = get_similar_flow(user_input)\n",
    "\n",
    "if similar_qa[0] > 0:\n",
    "    prompt += \"\\nHere is \" + str(similar_qa[0]) + \" history questions and answers related to this question according to Flora's database:\\n\" + similar_qa[1] + \"\\n\"\n",
    "\n",
    "prompt = prompt + \"here is the user input \\n\" + user_input\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content = prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while run.status == \"queued\" or run.status == \"in_progress\":\n",
    "    run = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id\n",
    "    )\n",
    "print(run.status)\n",
    "# print(tabulate(run,headers=['run','content'],tablefmt='simple_outline'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)\n",
    "messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id,\n",
    "    order='asc'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in messages.data[-3:]:\n",
    "    print(i.content[0].text.value)\n",
    "    print(\"==========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.beta.assistants.delete(assistant.id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VScode-env-3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
