{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# phase 1 分完重點後，切換到對應的 thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "OpenAI.api_key = os.getenv('OPENAI_API_KEY')\n",
    "print(OpenAI.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "csv_file = './data/embeddingsV3_3072.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "index = faiss.IndexFlatL2(data.shape[1])\n",
    "index.add(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_qa(input):\n",
    "    response = client.embeddings.create(input=input, model=\"text-embedding-3-large\", dimensions=3072)\n",
    "    question = np.array(response.data[0].embedding, ndmin=2)\n",
    "    k = 3\n",
    "    distances, indices = index.search(question, k)\n",
    "    csv_question = 'data\\manual.csv'\n",
    "    qdf = pd.read_csv(csv_question)\n",
    "    qarray = qdf.to_numpy()\n",
    "    answer = [(qarray[i], float(dist)) for dist, i in zip(distances[0], indices[0])]\n",
    "    history = \"\"\n",
    "    min_distance = 1\n",
    "    Qcount = 0\n",
    "    for i in range(0,k):\n",
    "        if answer[i][1]<min_distance:\n",
    "            Qcount+=1\n",
    "            history = history +str(i+1)+\". \"+ answer[i][0][0]+\"\\n\"+answer[i][0][1]+\"\\n\"\n",
    "    return Qcount, history\n",
    "\n",
    "def get_similar_flow(input):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = [\n",
    "    \"You are Flora customer service chat bot. You are prohibited replying unrelated to Flora. \",\n",
    "    \"When user ask a question, You must reply based on 3 history questions and answers. \",\n",
    "    \"If 3 history questions and answers not related to my question, you must reply only a special mark:'*'. \",\n",
    "    \"If history answer have flow of steps inside, you must follow the flow, resolving the problem one step at a time. \",\n",
    "    \"If the user asks another question before the previous question is solved, focus dealing with the previous question and tell them to open another feedback request to solve thier other questions. \",\n",
    "    \"When you encounter user providing email, you must call check_email for verification. \"\n",
    "]\n",
    "\n",
    "instruction = \"\"\n",
    "for i in instructions:\n",
    "    instruction += i\n",
    "\n",
    "print(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name = \"Flora's Customer Service\",\n",
    "    instructions = instruction,\n",
    "    model = \"gpt-3.5-turbo-1106\",\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"check_email\",\n",
    "                \"description\": \"checking email is exist in our database or not.True represent exists and you can proceed next step.False represent not exist and you have to try asking user again\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"email\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"user's email\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"email\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = 1\n",
    "\n",
    "key_point = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat start from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一開始用 key point 給回應(init = 1)，後續是和 user 溝通 (init = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "follow_up_conversation = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\n",
    "\n",
    "if init == 1:\n",
    "    user_input = key_point\n",
    "    similar_qa = get_similar_qa(user_input)\n",
    "    similar_flow = get_similar_flow(user_input)\n",
    "\n",
    "    user_prompt += similar_flow\n",
    "\n",
    "    if similar_qa[0] > 0:\n",
    "        user_prompt += \"\\nHere is \" + str(similar_qa[0]) + \" history questions and answers related to this question according to Flora's database:\\n\" + similar_qa[1] + \"\\n\"\n",
    "\n",
    "    user_prompt = user_prompt + \"Here is the user input: \" + user_input\n",
    "elif init == 0:\n",
    "    user_input = follow_up_conversation\n",
    "    user_prompt = user_input\n",
    "\n",
    "init = 0\n",
    "print(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id = thread.id,\n",
    "    role = \"user\",\n",
    "    content = user_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id = thread.id,\n",
    "    assistant_id = assistant.id\n",
    ")\n",
    "\n",
    "while run.status == \"queued\" or run.status == \"in_progress\":\n",
    "    run = client.beta.threads.runs.retrieve(\n",
    "        thread_id = thread.id,\n",
    "        run_id = run.id\n",
    "    )\n",
    "print(run.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run.status == \"requires_action\":\n",
    "    if run.required_action.submit_tool_outputs.tool_calls[0].function.name == \"check_email\":\n",
    "        print(\"function calling: check_email\")\n",
    "        run = client.beta.threads.runs.submit_tool_outputs(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id,\n",
    "            tool_outputs=[\n",
    "                {\n",
    "                    \"tool_call_id\": run.required_action.submit_tool_outputs.tool_calls[0].id,\n",
    "                    \"output\": \"True\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "else:\n",
    "    print(\"No function calling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = client.beta.threads.messages.list(\n",
    "    thread_id = thread.id,\n",
    "    order = 'asc'\n",
    ")\n",
    "\n",
    "for i in messages.data[-10:]:\n",
    "    print(i.content[0].text.value)\n",
    "    print(\"==========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.beta.assistants.delete(assistant.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.beta.assistants.list(\n",
    "    order=\"desc\",\n",
    "    limit=\"20\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VScode-env-3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
