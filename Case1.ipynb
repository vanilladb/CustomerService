{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 1 說明\n",
    "只對第一個 user input 執行 RAG\n",
    "\n",
    "Retrieve flow and related QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from tabulate import tabulate\n",
    "client = OpenAI()\n",
    "OpenAI.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_47804\\2711399014.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "csv_file = 'data\\embeddingsV3_3072.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "data = df.to_numpy()\n",
    "\n",
    "index = faiss.IndexFlatL2(data.shape[1])\n",
    "index.add(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_qa(input):\n",
    "    response = client.embeddings.create(input=input, model=\"text-embedding-3-large\", dimensions=3072)\n",
    "    question = np.array(response.data[0].embedding, ndmin=2)\n",
    "    k = 3\n",
    "    distances, indices = index.search(question, k)\n",
    "    csv_question = 'data\\manual.csv'\n",
    "    qdf = pd.read_csv(csv_question)\n",
    "    qarray = qdf.to_numpy()\n",
    "    answer = [(qarray[i], float(dist)) for dist, i in zip(distances[0], indices[0])]\n",
    "    history = \"\"\n",
    "    min_distance = 1\n",
    "    Qcount = 0\n",
    "    for i in range(0,k):\n",
    "        if answer[i][1]<min_distance:\n",
    "            Qcount+=1\n",
    "            history = history +str(i+1)+\". \"+ answer[i][0][0]+\"\\n\"+answer[i][0][1]+\"\\n\"\n",
    "    return Qcount, history\n",
    "\n",
    "def get_similar_flow(input):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. You are Flora customer service chat bot. You are prohibited replying unrelated to Flora2. When user ask a question, you must follow the flow, resolving the problem one step at a time.3. If the user asks another question before the previous question is solved, deal with the new question first and then go back to the steps of the previous question for continued processing.4. When you encounter question concerning email, you must check email fitting RFC5322 standard or not. if not, ask again\n"
     ]
    }
   ],
   "source": [
    "instructions = [\n",
    "    \"1. You are Flora customer service chat bot. You are prohibited replying unrelated to Flora\",\n",
    "    \"2. When user ask a question, you must follow the flow, resolving the problem one step at a time.\",\n",
    "    \"3. If the user asks another question before the previous question is solved, deal with the new question first and then go back to the steps of the previous question for continued processing.\",\n",
    "    \"4. When you encounter question concerning email, you must check email fitting RFC5322 standard or not. if not, ask again\"\n",
    "]\n",
    "\n",
    "instruction = \"\"\n",
    "for i in instructions:\n",
    "    instruction += i\n",
    "\n",
    "print(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Flora's Customer Service\",\n",
    "    instructions=instruction,\n",
    "    model=\"gpt-3.5-turbo-1106\"\n",
    "    # tools = [\n",
    "    #     {\n",
    "    #         \"type\": \"function\",\n",
    "    #         \"function\": {\n",
    "    #             \"name\": \"get_history_question_and_answer\",\n",
    "    #             \"description\": \"Get 1 to 3 history questions and answers that is similar to current question\",\n",
    "    #             \"parameters\": {\n",
    "    #                 \"type\": \"object\",\n",
    "    #                 \"properties\": {\n",
    "    #                     \"current_question\": {\n",
    "    #                         \"type\": \"string\",\n",
    "    #                         \"description\": \"user's question\"\n",
    "    #                     }\n",
    "    #                 },\n",
    "    #                 \"required\": [\"current_question\"]\n",
    "    #             }\n",
    "    #         }\n",
    "    #     }\n",
    "    # ]\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow = [\n",
    "#     \"Follow the steps to answer questions, if another question comes out, deal with the current problem first, then go back to the step of previous issue if user ask again:\",\n",
    "#     \"Ask the user for their email.\",\n",
    "#     \"Ask the user for the time when the tree was killed.\",\n",
    "#     \"The last step, you must respond based on the reference answer of the user's initial question if history questions and reference answers are provided. If not, you must reply only a special mark:'*'.\"\n",
    "# ]\n",
    "\n",
    "'''\n",
    "ask user for their email;\n",
    "if(got user email){\n",
    "    ask user for the time when the tree was killed;\n",
    "    if(got the time){\n",
    "        respond based on the reference answer of the user's initial question if history questions and reference answers are provided. If not, you must reply only a special mark:'*'.\n",
    "    }\n",
    "    else{\n",
    "        ask the time again.\n",
    "    }\n",
    "}\n",
    "else{ask email again}\n",
    "'''\n",
    "\n",
    "flow = \"ask user for their email;if(got user email){ask user for the time when the tree was killed;if(got the time){respond based on the reference answer of the user's initial question if history questions and reference answers are provided. If not, you must reply only a special mark:'*'.}else{ask the time again.}}else{ask email again}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I accidentally killed my tree. Is there any way to restore it?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ask user for their email;if(got user email){ask user for the time when the tree was killed;if(got the time){respond based on the reference answer of the user's initial question if history questions and reference answers are provided. If not, you must reply only a special mark:'*'.}else{ask the time again.}}else{ask email again}\n",
      "Here is 3 history questions and answers related to this question according to Flora's database:\n",
      "1.  I just started using this app and was looking around trying to figure the features out and accidentally killed a tree. I don'twant that to be there permanently. Is there anything I can do?\n",
      "We currently don't support the function of deleting a story as we believe every record matters. If you get a dead tree because of the system error, you could inform us by reporting 'False Detection'(the ! icon on the top right corner on the tree dead page) or through this feedback system. We would correct the result for you.\n",
      "2. What's the best way to ensure my tree doesn't get killed? \n",
      "Though we have used a sophisticated algorithm for detection, it could still make a mistake sometimes due to different usage environments. Meanwhile, you can take the following steps to minimize the chance of false detection: (1) Do not press the home button before locking your phone during a focus session. Some people have this habit, but it kills the tree. Please leave the Flora app open. (2) Keep the version of your iOS and Flora app up to date. (3) Make sure you have a stable Internet connection. If you foresee connectivity issues, please grow a tree in the Offline Planting mode. (4) The iOS system may actively kill apps under some circumstances, such as when it faces memory pressure or when the phone is locked for a long time. If the Flora app is unfortunately killed by the iOS, your session will end. Flora will do its best to restore your focus session when it is opened again. However, please understand that we might not be able to always successfully recover your focus session due to iOS limitations. You can minimize the chance of an automatic shutdown by closing some memory-hungry apps (like games) in the background.\n",
      "3. I didn't leave Flora but my tree was still killed. What should I do?\n",
      "If you get your tree killed and think it was not your fault, please report a 'False Detection' by pressing the '!' (triangular exclamation) button at the upper-right corner of the red focus screen. If verifying that it is indeed a false detection, we will revive your tree. If we find any bug that leads to a false kill, we will fix it ASAP. Please be noted that this service requires an internet connection, therefore this option will not be available if you plant offline.Though we have used a sophisticated algorithm for detection, it could still make a mistake sometimes due to different usage environments. Meanwhile, you can take the following steps to minimize the chance of false detection: (1) Do not press the home button before locking your phone during a focus session. Some people have this habit, but it kills the tree. Please leave the Flora app open. (2) Keep the version of your iOS and Flora app up to date. (3) Make sure you have a stable Internet connection. If you foresee connectivity issues, please grow a tree in the Offline Planting mode. (4) The iOS system may actively kill apps under some circumstances, such as when it faces memory pressure or when the phone is locked for a long time. If the Flora app is unfortunately killed by the iOS, your session will end. Flora will do its best to restore your focus session when it is opened again. However, please understand that we might not be able to always successfully recover your focus session due to iOS limitations. You can minimize the chance of an automatic shutdown by closing some memory-hungry apps (like games) in the background.\n",
      "\n",
      "here is the user input \n",
      "I accidentally killed my tree. Is there any way to restore it?\n"
     ]
    }
   ],
   "source": [
    "# prompt = get_similar_flow(user_input) + get_similar_qa(user_input) + user_input\n",
    "\n",
    "prompt = \"\"\n",
    "\n",
    "# for i in flow:\n",
    "#     prompt = prompt + i + \"\\n\"\n",
    "\n",
    "prompt += flow\n",
    "\n",
    "similar_qa = get_similar_qa(user_input)\n",
    "similar_flow = get_similar_flow(user_input)\n",
    "\n",
    "if similar_qa[0] > 0:\n",
    "    prompt += \"\\nHere is \" + str(similar_qa[0]) + \" history questions and answers related to this question according to Flora's database:\\n\" + similar_qa[1] + \"\\n\"\n",
    "\n",
    "prompt = prompt + \"here is the user input \\n\" + user_input\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content = prompt\n",
    "    #content = \"Iambigashell.gg.ez\"\n",
    "    #content = \"It's around 4:00 PM on March 28th.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "while run.status == \"queued\" or run.status == \"in_progress\":\n",
    "    run = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id\n",
    "    )\n",
    "print(run.status)\n",
    "# print(tabulate(run,headers=['run','content'],tablefmt='simple_outline'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)\n",
    "messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id,\n",
    "    order='asc'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ask user for their email;if(got user email){ask user for the time when the tree was killed;if(got the time){respond based on the reference answer of the user's initial question if history questions and reference answers are provided. If not, you must reply only a special mark:'*'.}else{ask the time again.}}else{ask email again}\n",
      "Here is 3 history questions and answers related to this question according to Flora's database:\n",
      "1.  I just started using this app and was looking around trying to figure the features out and accidentally killed a tree. I don'twant that to be there permanently. Is there anything I can do?\n",
      "We currently don't support the function of deleting a story as we believe every record matters. If you get a dead tree because of the system error, you could inform us by reporting 'False Detection'(the ! icon on the top right corner on the tree dead page) or through this feedback system. We would correct the result for you.\n",
      "2. What's the best way to ensure my tree doesn't get killed? \n",
      "Though we have used a sophisticated algorithm for detection, it could still make a mistake sometimes due to different usage environments. Meanwhile, you can take the following steps to minimize the chance of false detection: (1) Do not press the home button before locking your phone during a focus session. Some people have this habit, but it kills the tree. Please leave the Flora app open. (2) Keep the version of your iOS and Flora app up to date. (3) Make sure you have a stable Internet connection. If you foresee connectivity issues, please grow a tree in the Offline Planting mode. (4) The iOS system may actively kill apps under some circumstances, such as when it faces memory pressure or when the phone is locked for a long time. If the Flora app is unfortunately killed by the iOS, your session will end. Flora will do its best to restore your focus session when it is opened again. However, please understand that we might not be able to always successfully recover your focus session due to iOS limitations. You can minimize the chance of an automatic shutdown by closing some memory-hungry apps (like games) in the background.\n",
      "3. I didn't leave Flora but my tree was still killed. What should I do?\n",
      "If you get your tree killed and think it was not your fault, please report a 'False Detection' by pressing the '!' (triangular exclamation) button at the upper-right corner of the red focus screen. If verifying that it is indeed a false detection, we will revive your tree. If we find any bug that leads to a false kill, we will fix it ASAP. Please be noted that this service requires an internet connection, therefore this option will not be available if you plant offline.Though we have used a sophisticated algorithm for detection, it could still make a mistake sometimes due to different usage environments. Meanwhile, you can take the following steps to minimize the chance of false detection: (1) Do not press the home button before locking your phone during a focus session. Some people have this habit, but it kills the tree. Please leave the Flora app open. (2) Keep the version of your iOS and Flora app up to date. (3) Make sure you have a stable Internet connection. If you foresee connectivity issues, please grow a tree in the Offline Planting mode. (4) The iOS system may actively kill apps under some circumstances, such as when it faces memory pressure or when the phone is locked for a long time. If the Flora app is unfortunately killed by the iOS, your session will end. Flora will do its best to restore your focus session when it is opened again. However, please understand that we might not be able to always successfully recover your focus session due to iOS limitations. You can minimize the chance of an automatic shutdown by closing some memory-hungry apps (like games) in the background.\n",
      "\n",
      "here is the user input \n",
      "I accidentally killed my tree. Is there any way to restore it?\n",
      "==========\n",
      "I'm sorry to hear that your tree was killed. Could you please provide me with your email address associated with your Flora account?\n",
      "==========\n",
      "Iambigashell.gg.ez\n",
      "==========\n",
      "I'm sorry, but that does not appear to be a valid email address. Could you please provide a valid email address associated with your Flora account?\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "for i in messages.data[-5:]:\n",
    "    print(i.content[0].text.value)\n",
    "    print(\"==========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AssistantDeleted(id='asst_TSaRSWPCoIhNlQ884xji7KRD', deleted=True, object='assistant.deleted')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.beta.assistants.delete(assistant.id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VScode-env-3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
